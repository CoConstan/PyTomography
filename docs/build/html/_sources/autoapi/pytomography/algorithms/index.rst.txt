:py:mod:`pytomography.algorithms`
=================================

.. py:module:: pytomography.algorithms

.. autoapi-nested-parse::

   This module contains all the available reconstruction algorithms in PyTomography.



Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   dip_recon/index.rst
   fbp/index.rst
   preconditioned_gradient_ascent/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   pytomography.algorithms.PreconditionedGradientAscentAlgorithm
   pytomography.algorithms.OSEM
   pytomography.algorithms.OSMAPOSL
   pytomography.algorithms.BSREM
   pytomography.algorithms.KEM
   pytomography.algorithms.FilteredBackProjection
   pytomography.algorithms.DIPRecon




.. py:class:: PreconditionedGradientAscentAlgorithm(likelihood, prior = None, object_initial = None, norm_BP_subset_method = 'subset_specific', **kwargs)

   Generic class for preconditioned gradient ascent algorithms: i.e. those that have the form :math:`f^{n+1} = f^{n} + C^{n}(f^{n}) \left[\nabla_{f} L(g^n|f^{n}) - \beta \nabla_{f} V(f^{n}) \right]`.

   :param likelihood: Likelihood class that facilitates computation of :math:`L(g^n|f^{n})` and its associated derivatives.
   :type likelihood: Likelihood
   :param prior: Prior class that faciliates the computation of function :math:`V(f)` and its associated derivatives. If None, then no prior is used Defaults to None.
   :type prior: Prior, optional
   :param object_initial: Initial object for reconstruction algorithm. If None, then an object with 1 in every voxel is used. Defaults to None.
   :type object_initial: torch.Tensor | None, optional
   :param norm_BP_subset_method: Specifies how :math:`H^T 1` is calculated when subsets are used. If 'subset_specific', then uses :math:`H_n^T 1`. If `average_of_subsets`, then uses the average of all :math:`H_n^T 1`s for any given subset (scaled to the relative size of the subset if subsets are not equal size). Defaults to 'subset_specific'.
   :type norm_BP_subset_method: str, optional

   .. py:method:: _set_n_subsets(n_subsets)

      Sets the number of subsets used in the reconstruction algorithm.

      :param n_subsets: Number of subsets
      :type n_subsets: int


   .. py:method:: _compute_preconditioner(object, n_iter, n_subset)
      :abstractmethod:

      Computes the preconditioner factor :math:`C^{n}(f^{n})`. Must be implemented by any reconstruction algorithm that inherits from this generic class.

      :param object: Object :math:`f^n`
      :type object: torch.Tensor
      :param n_iter: Iteration number
      :type n_iter: int
      :param n_subset: Subset number
      :type n_subset: int

      :raises NotImplementedError: .


   .. py:method:: _compute_callback(n_iter, n_subset)

      Method for computing callbacks after each reconstruction iteration

      :param n_iter: Number of iterations
      :type n_iter: int
      :param n_subset: Number of subsets
      :type n_subset: int


   .. py:method:: __call__(n_iters, n_subsets, n_subset_specific = None, callback = None)

      _summary_

      :param Args:
      :param n_iters: Number of iterations
      :type n_iters: int
      :param n_subsets: Number of subsets
      :type n_subsets: int
      :param n_subset_specific: Ignore all updates except for this subset.
      :type n_subset_specific: int
      :param callback: Callback function to be called after each subiteration. Defaults to None.
      :type callback: Callback, optional

      :returns: Reconstructed object.
      :rtype: torch.Tensor



.. py:class:: OSEM(likelihood, object_initial = None)

   Bases: :py:obj:`LinearPreconditionedGradientAscentAlgorithm`

   Implementation of the ordered subset expectation maximum algorithm :math:`f^{n+1} = f^{n} + \frac{f^n}{H_n^T} \nabla_{f} L(g^n|f^{n})`.

   :param likelihood: Likelihood function :math:`L`.
   :type likelihood: Likelihood
   :param object_initial: Initial object for reconstruction algorithm. If None, then an object with 1 in every voxel is used. Defaults to None.
   :type object_initial: torch.Tensor | None, optional

   .. py:method:: _linear_preconditioner_factor(n_iter, n_subset)

      Computes the linear preconditioner factor :math:`D^n = 1/H_n^T 1`

      :param n_iter: iteration number
      :type n_iter: int
      :param n_subset: subset number
      :type n_subset: int

      :returns: linear preconditioner factor
      :rtype: torch.Tensor



.. py:class:: OSMAPOSL(likelihood, object_initial = None, prior = None)

   Bases: :py:obj:`PreconditionedGradientAscentAlgorithm`

   Implementation of the ordered subset maximum a posteriori one step late algorithm :math:`f^{n+1} = f^{n} + \frac{f^n}{H_n^T+\nabla_f V(f^n)} \left[ \nabla_{f} L(g^n|f^{n}) - \nabla_f V(f^n) \right]`

   :param likelihood: Likelihood function :math:`L`.
   :type likelihood: Likelihood
   :param object_initial: Initial object for reconstruction algorithm. If None, then an object with 1 in every voxel is used. Defaults to None.
   :type object_initial: torch.Tensor | None, optional
   :param prior: Prior class that faciliates the computation of function :math:`V(f)` and its associated derivatives. If None, then no prior is used. Defaults to None.
   :type prior: Prior, optional

   .. py:method:: _compute_preconditioner(object, n_iter, n_subset)

      Computes the preconditioner factor :math:`C^n(f^n) = \frac{f^n}{H_n^T+\nabla_f V(f^n)}`

      :param object: Object estimate :math:`f^n`
      :type object: torch.Tensor
      :param n_iter: iteration number
      :type n_iter: int
      :param n_subset: subset number
      :type n_subset: int

      :returns: preconditioner factor.
      :rtype: torch.Tensor



.. py:class:: BSREM(likelihood, object_initial = None, prior = None, relaxation_sequence = lambda _: 1)

   Bases: :py:obj:`LinearPreconditionedGradientAscentAlgorithm`

   Implementation of the block sequential regularized expectation maximum algorithm :math:`f^{n+1} = f^{n} + \frac{\alpha(n)}{\omega_n H^T 1} \left[\nabla_{f} L(g^n|f^{n}) - \nabla_f V(f^n) \right]`

   :param likelihood: likelihood function :math:`L`
   :type likelihood: Likelihood
   :param object_initial: Initial object for reconstruction algorithm. If None, then an object with 1 in every voxel is used. Defaults to None.
   :type object_initial: torch.Tensor | None, optional
   :param prior: Prior class that faciliates the computation of function :math:`V(f)` and its associated derivatives. If None, then no prior is used. Defaults to None.
   :type prior: Prior, optional
   :param relaxation_sequence: Relxation sequence :math:`\alpha(n)` used to scale future updates. Defaults to 1 for all :math:`n`. Note that when this function is provided, it takes the iteration number (not the subiteration) so that e.g. if 4 iterations and 8 subsets are used, it would call :math:`\alpha(4)` for all 8 subiterations of the final iteration.
   :type relaxation_sequence: Callable, optional

   .. py:method:: _linear_preconditioner_factor(n_iter, n_subset)

      Computes the linear preconditioner factor :math:`D^n = 1/(\omega_n H^T 1)` where :math:`\omega_n` corresponds to the fraction of subsets at subiteration :math:`n`.

      :param n_iter: iteration number
      :type n_iter: int
      :param n_subset: subset number
      :type n_subset: int

      :returns: linear preconditioner factor
      :rtype: torch.Tensor



.. py:class:: KEM(likelihood, object_initial = None)

   Bases: :py:obj:`OSEM`

   Implementation of the ordered subset expectation maximum algorithm :math:`\alpha^{n+1} = \alpha^{n} + \frac{\alpha^n}{\tilde{H}_n^T} \nabla_{f} L(g^n|\alpha^{n})` and where the final predicted object is :math:`f^n = K \hat{\alpha}^{n}`. The system matrix :math:`\tilde{H}` includes the kernel transform :math:`K`.

   :param likelihood: Likelihood function :math:`L`.
   :type likelihood: Likelihood
   :param object_initial: Initial object for reconstruction algorithm. If None, then an object with 1 in every voxel is used. Defaults to None.
   :type object_initial: torch.Tensor | None, optional

   .. py:method:: _compute_callback(n_iter, n_subset)

      Method for computing callbacks after each reconstruction iteration. This is reimplemented for KEM because the callback needs to be called on :math:`f^n = K \hat{\alpha}^{n}` as opposed to :math:`\hat{\alpha}^{n}`

      :param n_iter: Number of iterations
      :type n_iter: int
      :param n_subset: Number of subsets
      :type n_subset: int


   .. py:method:: __call__(*args, **kwargs)

      Reimplementation of the call method such that :math:`f^n = K \hat{\alpha}^{n}` is returned as opposed to :math:`\hat{\alpha}^{n}`

      :returns: reconstructed object
      :rtype: torch.Tensor



.. py:class:: FilteredBackProjection(projections, angles, filter=None)

   Implementation of filtered back projection reconstruction :math:`\hat{f} = \frac{\pi}{N_{\text{proj}}} \mathcal{R}^{-1}\mathcal{F}^{-1}\Pi\mathcal{F} g` where :math:`N_{\text{proj}}` is the number of projections, :math:`\mathcal{R}` is the 3D radon transform, :math:`\mathcal{F}` is the 2D Fourier transform (applied to each projection seperately), and :math:`\Pi` is the filter applied in Fourier space, which is by default the ramp filter.

   :param projections: projection data :math:`g` to be reconstructed
   :type projections: torch.Tensor
   :param angles: Angles corresponding to each projection
   :type angles: Sequence
   :param filter: Additional Fourier space filter (applied after Ramp Filter) used during reconstruction.
   :type filter: Callable, optional

   .. py:method:: __call__()

      Applies reconstruction

      :returns: Reconstructed object prediction
      :rtype: torch.tensor



.. py:class:: DIPRecon(likelihood, prior_network, rho = 0.003, EM_algorithm=OSEM)

   Implementation of the Deep Image Prior reconstruction technique (see https://ieeexplore.ieee.org/document/8581448). This reconstruction technique requires an instance of a user-defined ``prior_network`` that implements two functions: (i) a ``fit`` method that takes in an ``object`` (:math:`x`) which the network ``f(z;\theta)`` is subsequently fit to, and (ii) a ``predict`` function that returns the current network prediction :math:`f(z;\theta)`. For more details, see the Deep Image Prior tutorial.

   :param projections: projection data :math:`g` to be reconstructed
   :type projections: torch.tensor
   :param system_matrix: System matrix :math:`H` used in :math:`g=Hf`.
   :type system_matrix: SystemMatrix
   :param prior_network: User defined prior network that implements the neural network ``f(z;\theta)``
   :type prior_network: nn.Module
   :param rho: Value of :math:`\rho` used in the optimization procedure. Defaults to 1.
   :type rho: float, optional
   :param scatter: Projection space scatter estimate. Defaults to 0.
   :type scatter: torch.tensor | float, optional
   :param precompute_normalization_factors: Whether to precompute :math:`H_m^T 1` and store on GPU in the OSEM network before reconstruction. Defaults to True.
   :type precompute_normalization_factors: bool, optional

   .. py:method:: _compute_callback(n_iter, n_subset)

      Method for computing callbacks after each reconstruction iteration

      :param n_iter: Number of iterations
      :type n_iter: int
      :param n_subset: Number of subsets
      :type n_subset: int


   .. py:method:: __call__(n_iters, subit1, n_subsets_osem=1, callback=None)

      Implementation of Algorithm 1 in https://ieeexplore.ieee.org/document/8581448. This implementation gives the additional option to use ordered subsets. The quantity SubIt2 specified in the paper is controlled by the user-defined ``prior_network`` class.

      :param n_iters: Number of iterations (MaxIt in paper)
      :type n_iters: int
      :param subit1: Number of OSEM iterations before retraining neural network (SubIt1 in paper)
      :type subit1: int
      :param n_subsets_osem: Number of subsets to use in OSEM reconstruction. Defaults to 1.
      :type n_subsets_osem: int, optional

      :returns: Reconstructed image
      :rtype: torch.Tensor



